# [Learning to learn to gradient descent by gradient descent 2016](https://arxiv.org/pdf/1606.04474v2.pdf)
Optimization algorithms are still designed by hand. This paper casts optimization problem design as a learning problem
- Hessian Matrix corrects naive gradient descent by accounting for second order information
- convex optimization is a subfield of optimization, minimizing convex functions over convex sets
- deep learning has seen a proliferation of optimization methods for high dimensional, non convex optimization problems
